{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from scipy.interpolate import RBFInterpolator, LinearNDInterpolator\n",
    "\n",
    "from string import ascii_letters\n",
    "import random\n",
    "\n",
    "import perturbations\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "api_key = pd.read_csv('/mnt/c/Users/hhelm/Documents/Helivan/Organization/helivan.csv').iloc[0]['key']\n",
    "CLIENT = OpenAI(api_key=api_key)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomInsertionPerturbation(perturbations.Perturbation):\n",
    "    def __init__(self, length_of_insertions, insertion_key=None, alphabet=ascii_letters, max_insertions=1):\n",
    "        self.length_of_insertions=length_of_insertions\n",
    "        \n",
    "        if insertion_key is None:\n",
    "            self.insertion_key= ' ' \n",
    "        else:\n",
    "            self.insertion_key=insertion_key\n",
    "            \n",
    "        self.alphabet=alphabet\n",
    "            \n",
    "        assert isinstance(max_insertions, int)\n",
    "        assert max_insertions > 0\n",
    "        \n",
    "        self.max_insertions=max_insertions\n",
    "        self._get_insertions()\n",
    "           \n",
    "    def _get_insertions(self):\n",
    "        self.insertions=[]\n",
    "        \n",
    "        for i in range(self.max_insertions):\n",
    "            s=\"\"\n",
    "            for j in range(self.length_of_insertions):\n",
    "                s+=random.choice(self.alphabet)\n",
    "            self.insertions.append(s)\n",
    "            \n",
    "    def perturb(self, string, new_insertions=False):\n",
    "        self._check_string(string)\n",
    "        \n",
    "        if new_insertions:\n",
    "            self._get_insertions()\n",
    "        \n",
    "        splits = string.split(self.insertion_key)\n",
    "        \n",
    "        if len(splits)==1:\n",
    "            return string + ' ' + self.insertions[0]\n",
    "        \n",
    "        if self.max_insertions > len(splits):\n",
    "            max_insertions=len(splits)\n",
    "        else:\n",
    "            max_insertions=self.max_insertions\n",
    "        \n",
    "        insert_indices = np.random.choice(len(splits)-1, max_insertions, replace=False)\n",
    "        \n",
    "        for i, split_ind in enumerate(insert_indices):\n",
    "            splits[split_ind] += self.insertion_key \n",
    "            splits[split_ind] += ' ' + self.insertions[i] + ' '\n",
    "            \n",
    "        perturbed_string = ''\n",
    "        for s in splits:\n",
    "            perturbed_string += s\n",
    "            \n",
    "        perturbed_string = perturbed_string.replace(\"  \", \" \")\n",
    "        \n",
    "        return perturbed_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>options</th>\n",
       "      <th>meta_info</th>\n",
       "      <th>answer_idx</th>\n",
       "      <th>metamap_phrases</th>\n",
       "      <th>mentions_pain</th>\n",
       "      <th>race</th>\n",
       "      <th>prompt</th>\n",
       "      <th>intervened_prompt_race=African American</th>\n",
       "      <th>intervened_prompt_race=Caucasian</th>\n",
       "      <th>model_responses_race=African American</th>\n",
       "      <th>model_responses_race=Caucasian</th>\n",
       "      <th>model_answers_race=African American</th>\n",
       "      <th>model_answers_race=Caucasian</th>\n",
       "      <th>model_answers_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>A 53-year-old man comes to the emergency depar...</td>\n",
       "      <td>Urinary pH: 4.7</td>\n",
       "      <td>{'A': 'Urinary pH: 7.3', 'B': 'Urinary pH: 4.7...</td>\n",
       "      <td>step2&amp;3</td>\n",
       "      <td>B</td>\n",
       "      <td>['year old man', 'emergency department', 'of s...</td>\n",
       "      <td>True</td>\n",
       "      <td>The text does not provide information about th...</td>\n",
       "      <td>A 53-year-old man comes to the emergency depar...</td>\n",
       "      <td>An African American 53-year-old man comes to t...</td>\n",
       "      <td>A 53-year-old Caucasian man comes to the emerg...</td>\n",
       "      <td>[\"The patient's symptoms (severe colicky pain ...</td>\n",
       "      <td>[\"This patient's severe, colicky, right-sided ...</td>\n",
       "      <td>['B', 'B', 'B', 'B', 'B']</td>\n",
       "      <td>['B', 'A', 'B', 'A', 'A']</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           question  \\\n",
       "0          25  A 53-year-old man comes to the emergency depar...   \n",
       "\n",
       "            answer                                            options  \\\n",
       "0  Urinary pH: 4.7  {'A': 'Urinary pH: 7.3', 'B': 'Urinary pH: 4.7...   \n",
       "\n",
       "  meta_info answer_idx                                    metamap_phrases  \\\n",
       "0   step2&3          B  ['year old man', 'emergency department', 'of s...   \n",
       "\n",
       "   mentions_pain                                               race  \\\n",
       "0           True  The text does not provide information about th...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  A 53-year-old man comes to the emergency depar...   \n",
       "\n",
       "             intervened_prompt_race=African American  \\\n",
       "0  An African American 53-year-old man comes to t...   \n",
       "\n",
       "                    intervened_prompt_race=Caucasian  \\\n",
       "0  A 53-year-old Caucasian man comes to the emerg...   \n",
       "\n",
       "               model_responses_race=African American  \\\n",
       "0  [\"The patient's symptoms (severe colicky pain ...   \n",
       "\n",
       "                      model_responses_race=Caucasian  \\\n",
       "0  [\"This patient's severe, colicky, right-sided ...   \n",
       "\n",
       "  model_answers_race=African American model_answers_race=Caucasian  \\\n",
       "0           ['B', 'B', 'B', 'B', 'B']    ['B', 'A', 'B', 'A', 'A']   \n",
       "\n",
       "   model_answers_diff  \n",
       "0                   6  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medical_qas = pd.read_csv('/mnt/c/Users/hhelm/Documents/Helivan/Software/medqa_pain_top_10.csv')\n",
    "question_list = list(medical_qas['question'])\n",
    "answer_idx_list = list(medical_qas['answer_idx'])\n",
    "options_list = list(medical_qas['options'])\n",
    "\n",
    "medical_qas.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "#- Generate perturbations\n",
    "n_perturbations=25\n",
    "insertion_key = 'year-old'\n",
    "alphabet=ascii_letters\n",
    "max_insertions=1\n",
    "\n",
    "length_list = [0, 1, 10, 100, 1000]\n",
    "perturb_dict = {}\n",
    "\n",
    "insertions = []\n",
    "for i in range(n_perturbations):\n",
    "    s=\"\"\n",
    "    for j in range(max(length_list)):\n",
    "        s+=random.choice(ascii_letters)\n",
    "    insertions.append(s)\n",
    "\n",
    "\n",
    "for length in length_list:\n",
    "    perturb_dict[length] = {}\n",
    "                      \n",
    "    for question in question_list:\n",
    "        perturb_dict[length][question] = {}\n",
    "        perturber = RandomInsertionPerturbation(length, insertion_key, alphabet, max_insertions)\n",
    "        \n",
    "        if length == 0:\n",
    "            perturb_dict[length][question][0] = question\n",
    "            continue\n",
    "\n",
    "        for i in range(n_perturbations):\n",
    "            perturber.insertions = [insertions[i][:length]]\n",
    "            perturb_dict[length][question][i] = perturber.perturb(question, new_insertions=False)\n",
    "\n",
    "\n",
    "#- Generate interventions\n",
    "intervention_list = ['Caucasian', 'White', 'of European descent', 'Western']\n",
    "intervention_dict = {}  \n",
    "\n",
    "for intervention in intervention_list:\n",
    "    intervention_dict[intervention] = {}\n",
    "    perturber = RandomInsertionPerturbation(len(intervention), insertion_key, alphabet, max_insertions)\n",
    "    \n",
    "    for question in question_list:\n",
    "        intervention_dict[intervention][question] = {}        \n",
    "        perturber.insertions = [intervention]\n",
    "\n",
    "        intervention_dict[intervention][question]['baseline'] = perturber.perturb(question)\n",
    "        \n",
    "        for i in range(n_perturbations):\n",
    "            intervention_dict[intervention][question][i] = perturber.perturb(question, new_insertions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIONS=['A', 'B', 'C', 'D']\n",
    "\n",
    "def options_to_dict(options):\n",
    "    dic={}\n",
    "        \n",
    "    splits = options.split('{')[-1]\n",
    "    splits = splits.split('}')[0]\n",
    "    \n",
    "    splits = splits.split(':')\n",
    "            \n",
    "    for s in splits:\n",
    "        key_and_value = s.split(':')\n",
    "        key = key_and_value[0][-2:-1]\n",
    "        value = key_and_value[1][2:-1]\n",
    "        dic[key]=value\n",
    "        \n",
    "    key_and_value = splits[-1].split(':')\n",
    "    key = key_and_value[0][-2:-1]\n",
    "    value = key_and_value[1][2:-2]\n",
    "\n",
    "        \n",
    "    dic[key]=value\n",
    "        \n",
    "    return dic\n",
    "\n",
    "\n",
    "def get_user_content(question, options):\n",
    "    return f'{question} {options}'\n",
    "\n",
    "\n",
    "def get_user_content_with_terse_answer(question, options, n_options=4):\n",
    "    if n_options is None:    \n",
    "        n_options = len(options)\n",
    "    \n",
    "    s = \"Please answer only with the letters\"\n",
    "    for i in range(n_options-1):\n",
    "        s+= f' \"{OPTIONS[i]}\",'\n",
    "        \n",
    "    s+= f' or \"{OPTIONS[n_options-1]}\".'\n",
    "        \n",
    "    \n",
    "    return f'{question} {s} {options}'\n",
    "\n",
    "\n",
    "def get_letter_response(response):\n",
    "    response = response.split('.')[0]\n",
    "    if response in OPTIONS:\n",
    "        return response\n",
    "    \n",
    "    response = response.split(':')[0]\n",
    "    if response in OPTIONS:\n",
    "        return response\n",
    "    \n",
    "    response = response.split('(')[0][0]\n",
    "    if response in OPTIONS:\n",
    "        return response\n",
    "    \n",
    "\n",
    "def parse_terse_responses(responses, options_list):\n",
    "    model_dump = responses.model_dump()['choices']\n",
    "    n_responses = len(model_dump)\n",
    "    \n",
    "    response_strings = [choice['message']['content'] for choice in model_dump]\n",
    "    response_dict = {k: 0 for k in options_list}\n",
    "    \n",
    "    \n",
    "    for response in response_strings:\n",
    "        response = get_letter_response(response)\n",
    "        if response in options_list:\n",
    "            response_dict[response] += 1\n",
    "    \n",
    "    return response_dict\n",
    "\n",
    "\n",
    "def get_responses(model_string, system_content, user_content, generation_kwargs={'temperature': 1, 'n':1}):\n",
    "    responses = CLIENT.chat.completions.create(\n",
    "      model=model_string,\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": system_content},\n",
    "        {\"role\": \"user\", \"content\": user_content}\n",
    "      ], \n",
    "        **generation_kwargs\n",
    "    )\n",
    "    \n",
    "    return responses\n",
    "\n",
    "\n",
    "def get_embeddings(input_string_list, model_string='text-embedding-ada-002'):\n",
    "    embds = CLIENT.embeddings.create(input=input_string_list, model=model_string)\n",
    "    embds = np.array([d.embedding for d in embds.data])\n",
    "    \n",
    "    if len(input_string_list)==1:\n",
    "        return embds[0]\n",
    "    else:\n",
    "        return embds\n",
    "    \n",
    "\n",
    "def get_distributions(prompt, model_string, system_content, generation_kwargs, options_as_list):\n",
    "    user_content = get_user_content_with_terse_answer(prompt, options_string)\n",
    "    \n",
    "    responses=get_responses(model_string, system_content, user_content, generation_kwargs)\n",
    "    \n",
    "    posterior = np.array(list(parse_terse_responses(responses, options_as_list).values())).astype(float)\n",
    "    posterior /= np.sum(posterior)\n",
    "    \n",
    "    return posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [00:19<00:00,  1.96s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [09:48<00:00, 58.80s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [10:02<00:00, 60.27s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [07:57<00:00, 47.78s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [20:36<00:00, 123.61s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [09:46<00:00, 58.67s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [08:01<00:00, 48.12s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [09:31<00:00, 57.15s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [08:15<00:00, 49.55s/it]\n"
     ]
    }
   ],
   "source": [
    "model_string = \"gpt-3.5-turbo\"\n",
    "embedding_model_string = 'text-embedding-ada-002'\n",
    "\n",
    "system_content = \"You are a helpful medical assistant.\"\n",
    "\n",
    "generation_kwargs = generation_kwargs={'temperature': 1, 'n': 50, 'seed':0}\n",
    "\n",
    "options_as_list = ['A', 'B', 'C', 'D']\n",
    "\n",
    "perturb_embeddings_dict = {}\n",
    "perturb_probs_dict = {}\n",
    "\n",
    "for length in length_list:\n",
    "    perturb_embeddings_dict[length] = {}\n",
    "    perturb_probs_dict[length] = {}\n",
    "        \n",
    "    for i, question in enumerate(tqdm(question_list)):\n",
    "        options_string = options_list[i]\n",
    "        \n",
    "        perturb_embeddings_dict[length][question] = {}\n",
    "        perturb_probs_dict[length][question] = {}\n",
    "        \n",
    "        for j in range(n_perturbations):\n",
    "            if length == 0 and j > 0:\n",
    "                continue\n",
    "            \n",
    "            temp_string = perturb_dict[length][question][j]\n",
    "            \n",
    "            perturb_embeddings_dict[length][question][j] = get_embeddings(temp_string, embedding_model_string)\n",
    "            \n",
    "            posterior = get_distributions(temp_string, model_string, system_content, generation_kwargs, options_as_list)\n",
    "            perturb_probs_dict[length][question][j] = posterior\n",
    "            \n",
    "        \n",
    "intervention_embeddings_dict = {}\n",
    "intervention_probs_dict = {}\n",
    "    \n",
    "for intervention in intervention_list:\n",
    "    intervention_embeddings_dict[intervention] = {}\n",
    "    intervention_probs_dict[intervention] = {}\n",
    "    \n",
    "    \n",
    "    for i, question in enumerate(tqdm(question_list)):\n",
    "        options_string = options_list[i]\n",
    "        \n",
    "        intervention_embeddings_dict[intervention][question] = {}\n",
    "        intervention_probs_dict[intervention][question] = {}\n",
    "        \n",
    "        temp_string = intervention_dict[intervention][question]['baseline']\n",
    "        intervention_embeddings_dict[intervention][question]['baseline'] = get_embeddings(temp_string, embedding_model_string)\n",
    "            \n",
    "        posterior = get_distributions(temp_string, model_string, system_content, generation_kwargs, options_as_list)            \n",
    "        intervention_probs_dict[intervention][question]['baseline'] = posterior\n",
    "        \n",
    "        \n",
    "        for j in range(n_perturbations):            \n",
    "            temp_string = intervention_dict[intervention][question][j]\n",
    "            \n",
    "            intervention_embeddings_dict[intervention][question][j] = get_embeddings(temp_string, embedding_model_string)\n",
    "            \n",
    "            posterior = get_distributions(temp_string, model_string, system_content, generation_kwargs, options_as_list)            \n",
    "            intervention_probs_dict[intervention][question][j] = posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "all_embeddings = {'interventions': intervention_embeddings_dict, 'perturbations': perturb_embeddings_dict}\n",
    "all_probs = {'interventions': intervention_probs_dict, 'perturbations': perturb_probs_dict}\n",
    "embeddings_and_probs = {'embeddings': all_embeddings, 'probs': all_probs}\n",
    "\n",
    "pickle.dump(embeddings_and_probs, open('/mnt/c/Users/hhelm/Documents/Helivan/Microsoft/data/embeddings_and_probs_medqa_10.p', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pnma",
   "language": "python",
   "name": "pnma"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
